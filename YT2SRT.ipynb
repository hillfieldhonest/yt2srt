{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3s2ZXL6RyPzD",
        "outputId": "2e4dbea1-f50f-4a52-aee1-463ba40524f8",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.9/171.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "You are ready to go!\n",
            "FYI: Cuda Availability: True\n"
          ]
        }
      ],
      "source": [
        "!pip install -q yt-dlp openai-whisper\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import whisper\n",
        "from IPython.display import Audio, display\n",
        "from google.colab import files\n",
        "import torch;\n",
        "\n",
        "print('You are ready to go!')\n",
        "print(f\"FYI: Cuda Availability: {torch.cuda.is_available()}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def download_youtube_audio(url, format='mp3'):\n",
        "    \"\"\"YouTube URLから音声をダウンロードする関数 (yt-dlp を使用)\"\"\"\n",
        "    if not url:\n",
        "        print('URLが入力されていません。')\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        # Colab 上で使う作業ディレクトリ例（お好みで変更可）\n",
        "        workspace_dir = '/content/whisper_workspace'\n",
        "        os.makedirs(workspace_dir, exist_ok=True)\n",
        "        os.chdir(workspace_dir)\n",
        "\n",
        "        # 動画IDを抽出して出力テンプレートを作成\n",
        "        # 例: youtube_XXXXXXXXXXX.mp3\n",
        "        video_id = url.split('watch?v=')[-1][:11]\n",
        "        output_template = f'youtube_{video_id}.%(ext)s'\n",
        "\n",
        "        # yt-dlp コマンド（指定のオプションを含む）\n",
        "        command = (\n",
        "            f\"yt-dlp \"\n",
        "            f\"--hls-use-mpegts \"\n",
        "            f\"--force-overwrites \"\n",
        "            f\"-x --audio-format {format} \"\n",
        "            f\"-o '{output_template}' \"\n",
        "            f\"'{url}'\"\n",
        "        )\n",
        "        print('音声ダウンロード中...')\n",
        "        subprocess.run(command, shell=True, check=True)\n",
        "\n",
        "        # ダウンロードされたファイルが想定通り存在するか確認\n",
        "        expected_file = f'youtube_{video_id}.{format}'\n",
        "        if os.path.exists(expected_file):\n",
        "            abs_path = os.path.abspath(expected_file)\n",
        "            print(f'ダウンロード完了: {abs_path}')\n",
        "            return abs_path\n",
        "        else:\n",
        "            print('音声ファイルが見つかりませんでした。')\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f'エラーが発生しました: {str(e)}')\n",
        "        return None\n",
        "def generate_srt(\n",
        "    audio_file: str,\n",
        "    model_size: str = \"turbo\",\n",
        "    language: str = \"auto\"\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    openai-whisper を使って音声ファイル (mp3 など) から文字起こしをし、\n",
        "    SRT形式の字幕ファイルを生成してパスを返す。\n",
        "    \"\"\"\n",
        "\n",
        "    if not os.path.exists(audio_file):\n",
        "        print(f\"音声ファイルが見つかりません: {audio_file}\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        # Whisper モデルをロード (初回実行時はモデルの自動ダウンロードが入る)\n",
        "        print(f\"Whisper モデル '{model_size}' をロードしています...\")\n",
        "        model = whisper.load_model(model_size)\n",
        "\n",
        "        # language='auto' としたい場合は引数を付けないなどで切り替え\n",
        "        if language.lower() == \"auto\":\n",
        "            result = model.transcribe(audio_file)\n",
        "        else:\n",
        "            result = model.transcribe(audio_file, language=language)\n",
        "\n",
        "        # SRT ファイル名は元ファイル名の拡張子だけ差し替える例\n",
        "        base_name = os.path.splitext(audio_file)[0]\n",
        "        srt_path = f\"{base_name}.srt\"\n",
        "\n",
        "        # 結果を SRT 形式で書き出し\n",
        "        write_srt(result[\"segments\"], srt_path)\n",
        "        print(f\"SRTファイルを生成しました: {srt_path}\")\n",
        "\n",
        "        return srt_path\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"エラーが発生しました: {e}\")\n",
        "        return\n",
        "\n",
        "def write_srt(segments, srt_path: str):\n",
        "    \"\"\"\n",
        "    Whisper の result[\"segments\"] をベースに、\n",
        "    シンプルに SRT 形式のファイルを生成するヘルパー関数。\n",
        "    \"\"\"\n",
        "    def sec_to_timestamp(sec: float):\n",
        "        hours = int(sec // 3600)\n",
        "        minutes = int((sec % 3600) // 60)\n",
        "        seconds = int(sec % 60)\n",
        "        milliseconds = int((sec - int(sec)) * 1000)\n",
        "        return f\"{hours:02}:{minutes:02}:{seconds:02},{milliseconds:03}\"\n",
        "\n",
        "    with open(srt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for i, seg in enumerate(segments, start=1):\n",
        "            start_time = sec_to_timestamp(seg[\"start\"])\n",
        "            end_time = sec_to_timestamp(seg[\"end\"])\n",
        "            text = seg[\"text\"].strip()\n",
        "            f.write(f\"{i}\\n\")\n",
        "            f.write(f\"{start_time} --> {end_time}\\n\")\n",
        "            f.write(f\"{text}\\n\\n\")\n",
        "\n",
        "def process_youtube_to_srt(url, audio_format='mp3', model_size='turbo', language='auto' ):\n",
        "    \"\"\"\n",
        "    1. 指定URL から音声をダウンロード\n",
        "    2. Whisper で字幕を生成 (SRT)\n",
        "    \"\"\"\n",
        "    # 1. ダウンロード（こちらが先ほど定義した関数）\n",
        "    audio_path = download_youtube_audio(url, format=audio_format)\n",
        "    if not audio_path:\n",
        "        print(\"音声ダウンロードに失敗しました。終了します。\")\n",
        "        return None\n",
        "\n",
        "    # 2. Whisper で字幕生成\n",
        "    print(\"字幕生成処理開始しました。...\")\n",
        "\n",
        "    srt_path = generate_srt(audio_path, model_size=model_size, language=language)\n",
        "\n",
        "    if not srt_path:\n",
        "        print(\"字幕生成に失敗しました。\")\n",
        "        return None\n",
        "\n",
        "    return srt_path\n",
        "\n"
      ],
      "metadata": {
        "id": "_1JvK8X2oVcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 実行例 (対話的)\n",
        "url = input('YouTube動画のURLを入力してください: ').strip()\n",
        "lang_input = input('言語コード (選択肢: ja, en, auto / デフォルト: auto): ').strip()\n",
        "language = lang_input if lang_input else 'auto'\n",
        "model_size_input = input('使用モデルサイズ (選択肢: tiny, base, small, medium, large, turbo / デフォルト: turbo): ').strip()\n",
        "model_size = model_size_input if model_size_input else 'turbo'\n",
        "\n",
        "srt_file = process_youtube_to_srt(\n",
        "    url=url,\n",
        "    audio_format='mp3',\n",
        "    model_size=model_size,   # Whisperのモデルサイズ\n",
        "    language=language,\n",
        ")\n",
        "\n",
        "# SRTファイルのDLリンク表示処理:\n",
        "if srt_file:\n",
        "    answer = input(\"お待たせしました！ 生成されたファイルをダウンロードしますか？ (y/n): \")\n",
        "    if answer.lower() == 'y':\n",
        "        files.download(srt_file)\n",
        "        print(\"Thank you for using! \")\n",
        "    else:\n",
        "        print(\"必要であれば、'/whisper_workspace' の下にファイルは保存されています。\")"
      ],
      "metadata": {
        "id": "uhP2AqPr0OXW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "8d7e27ca-9258-451a-dace-d6dba695fd45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YouTube動画のURLを入力してください: https://www.youtube.com/watch?v=KN0Cgt06ev4\n",
            "言語コード (選択肢: ja, en, auto / デフォルト: auto): \n",
            "使用モデルサイズ (選択肢: tiny, base, small, medium, large, turbo / デフォルト: turbo): large\n",
            "音声ダウンロード中...\n",
            "ダウンロード完了: /content/whisper_workspace/youtube_KN0Cgt06ev4.mp3\n",
            "字幕生成処理開始しました。...\n",
            "Whisper モデル 'large' をロードしています...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████████████████████████████████| 2.88G/2.88G [00:28<00:00, 109MiB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SRTファイルを生成しました: /content/whisper_workspace/youtube_KN0Cgt06ev4.srt\n",
            "お待たせしました！ 生成されたファイルをダウンロードしますか？ (y/n): y\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_751b2421-ef37-4ade-88ef-656f4d4011e5\", \"youtube_KN0Cgt06ev4.srt\", 39404)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thank you for using! \n"
          ]
        }
      ]
    }
  ]
}